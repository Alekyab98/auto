from datetime import datetime, timedelta, timezone
from airflow import DAG, AirflowException
from airflow.operators.dummy import DummyOperator
from airflow.operators.python import PythonOperator
from airflow.providers.google.cloud.operators.bigquery import BigQueryInsertJobOperator
from airflow.providers.google.cloud.hooks.bigquery import BigQueryHook
from functools import partial
import yaml
import os
import sys
import time

BASE_DIR = "/home/airflow/gcs/dags/vz-it-gudv-dtwndo-0"
sys.path.append(f"{BASE_DIR}/nqes_mobile/python")

from DO_utils import publishLog, create_do_dict

# ----------------------
# Load Config
# ----------------------
project = os.environ['GCP_PROJECT']

with open(f"{BASE_DIR}/nqes_mobile/config/base_config.yml", 'r') as file:
    base_config = yaml.full_load(file)

with open(f"{BASE_DIR}/nqes_mobile/config/gudv_nqes_mobile.yml", 'r') as file:
    dag_config = yaml.full_load(file)

config_values = {}

filtered_base_dict = dict(filter(lambda elem: elem[0] == project, base_config.items()))
filtered_dict = dict(filter(lambda elem: elem[0] == project, dag_config.items()))

if len(filtered_base_dict) > 0:
    base_value = filtered_base_dict[project][0]
    config_values = {**config_values, **base_value}
else:
    print("No config found. Exitingâ€¦")
    sys.exit(-1)

if len(filtered_dict) > 0:
    app_value = filtered_dict[project][0]
    config_values = {**config_values, **app_value}
else:
    print("No config found. Exitingâ€¦")
    sys.exit(-1)

# ----------------------
# Extract DAG variables
# ----------------------
GCP_PROJECT_ID = config_values['gcp_project']
bq_connection_id = config_values['google_cloud_conn_id']
region = config_values['region']
DAG_ID = config_values['dag_id']
base_directory = config_values['base_directory']
env = config_values['env']
dataset_id = config_values['dataset_id']
stored_proc = config_values['stored_proc']
table_name = config_values['table_name']
schedule_interval = config_values['schedule_interval']
failure_email_alert_distro = config_values['failure_email_alert_distro']

mobile_src_project_id = config_values['mobile_src_project_id']
mobile_src_dataset_id = config_values['mobile_src_dataset_id']
mobile_src_tbl_name = config_values['mobile_src_tbl_name']

# ----------------------
# Macros
# ----------------------
trans_date = '{{ (macros.datetime.strptime(data_interval_end.strftime("%Y-%m-%d"),"%Y-%m-%d") - macros.dateutil.relativedelta.relativedelta(days=1)).strftime("%Y-%m-%d") }}'
process_date = '{{ (macros.datetime.strptime(data_interval_end.strftime("%Y-%m-%d %H"),"%Y-%m-%d %H")).strftime("%Y-%m-%d") }}'


default_args = {
    'owner': 'airflow',
    'depends_on_past': False,
    'start_date': datetime(year=2025, month=4, day=30, hour=9, minute=0),
    'email': [failure_email_alert_distro],
    'email_on_failure': True,
    'email_on_retry': False,
    'retries': 3,
    'retry_delay': timedelta(minutes=3)
}

dag = DAG(
    dag_id=DAG_ID,
    schedule_interval=schedule_interval,
    catchup=True,
    default_args=default_args,
    description='This DAG calls NQES Mobile Stored Procedure',
    concurrency=int(config_values['concurrency']),
    max_active_runs=int(config_values['max_active_runs']),
    tags=["dtwin","nw_research_assistant","network_genie","nqes_mobile","auto_bi"]
)

do_dict = create_do_dict(config_values)


# =============================================================================
# NEW: Source Check with detailed failure logging
# =============================================================================

def check_sources_and_log(**context):
    """Check each required source individually and log the missing ones."""
    hook = BigQueryHook(gcp_conn_id=bq_connection_id, use_legacy_sql=False)
    ti = context["ti"]

    # Jinja resolved at runtime
    trans_dt = context["templates_dict"]["trans_date"]

    queries = {
        "ntwk_nqes_score":
            f"""SELECT COUNT(*) FROM `{mobile_src_project_id}.{mobile_src_dataset_id}.{mobile_src_tbl_name}`
                WHERE process_nm='ntwk_nqes_score'
                  AND status='COMPLETE'
                  AND run_dt=DATE('{trans_dt}')""",

        "ntwk_nqes_model_score":
            f"""SELECT COUNT(*) FROM `{mobile_src_project_id}.{mobile_src_dataset_id}.{mobile_src_tbl_name}`
                WHERE process_nm='ntwk_nqes_model_score'
                  AND status='COMPLETE'
                  AND run_dt=DATE('{trans_dt}')"""
    }

    missing_sources = []

    for src_name, sql in queries.items():
        df = hook.get_pandas_df(sql)
        count = df.iloc[0, 0]
        if count == 0:
            missing_sources.append(src_name)

    if missing_sources:
        details = f"Missing/empty sources: {', '.join(missing_sources)}"
        publishLog("FAILURE", {**do_dict, "details": details})
        raise AirflowException(details)

    publishLog("PROGRESS", {**do_dict, "details": "All required sources available"})


# =============================================================================
# Tasks
# =============================================================================

start = DummyOperator(
    task_id='start',
    dag=dag,
    on_success_callback=partial(publishLog, "PROGRESS", do_dict),
    on_failure_callback=partial(publishLog, "FAILURE", do_dict)
)

check_nqes_mobile_src_tbl_count_task = PythonOperator(
    task_id="check_nqes_mobile_src_tbl_count_task",
    python_callable=check_sources_and_log,
    templates_dict={"trans_date": trans_date},
    dag=dag
)

call_nqes_mobile_sp = BigQueryInsertJobOperator(
    task_id="call_nqes_mobile_sp",
    dag=dag,
    gcp_conn_id=bq_connection_id,
    configuration={
        "query": {
            "query": f"CALL {dataset_id}.{stored_proc}('{trans_date}','{process_date}')",
            "useLegacySql": False,
        }
    },
    on_failure_callback=partial(publishLog, "FAILURE", do_dict)
)

end = DummyOperator(
    task_id='end',
    dag=dag,
    on_success_callback=partial(publishLog, "SUCCESS", do_dict),
    on_failure_callback=partial(publishLog, "FAILURE", do_dict)
)

# DAG flow
start >> check_nqes_mobile_src_tbl_count_task >> call_nqes_mobile_sp >> end
